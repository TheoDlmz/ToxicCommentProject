{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ToxicModelCours1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbHj-RHAIVlN",
        "colab_type": "text"
      },
      "source": [
        "# I. Distinguer les commentaires gentils et méchants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CwG5iXDXkpR",
        "colab_type": "code",
        "outputId": "dad18c00-c800-4731-be55-451971557685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "!wget http://theo.delemazure.fr/perso/comments.csv\n",
        "!wget http://theo.delemazure.fr/perso/labels.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-25 09:31:01--  http://theo.delemazure.fr/perso/comments.csv\n",
            "Resolving theo.delemazure.fr (theo.delemazure.fr)... 217.160.0.80, 2001:8d8:100f:f000::267\n",
            "Connecting to theo.delemazure.fr (theo.delemazure.fr)|217.160.0.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 61471899 (59M) [text/csv]\n",
            "Saving to: ‘comments.csv’\n",
            "\n",
            "comments.csv        100%[===================>]  58.62M  45.9MB/s    in 1.3s    \n",
            "\n",
            "2020-04-25 09:31:03 (45.9 MB/s) - ‘comments.csv’ saved [61471899/61471899]\n",
            "\n",
            "--2020-04-25 09:31:04--  http://theo.delemazure.fr/perso/labels.csv\n",
            "Resolving theo.delemazure.fr (theo.delemazure.fr)... 217.160.0.80, 2001:8d8:100f:f000::267\n",
            "Connecting to theo.delemazure.fr (theo.delemazure.fr)|217.160.0.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3080081 (2.9M) [text/csv]\n",
            "Saving to: ‘labels.csv’\n",
            "\n",
            "labels.csv          100%[===================>]   2.94M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-04-25 09:31:04 (19.8 MB/s) - ‘labels.csv’ saved [3080081/3080081]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOihEwlmX20e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import torch \n",
        "import torch as th\n",
        "import torch.autograd as ag\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBu-ovfhYG_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COMMENT = 'comment_text'\n",
        "LIMIT = 20000\n",
        "comments = pd.read_csv('comments.csv')[COMMENT].to_numpy()[:LIMIT]\n",
        "labels = pd.read_csv('labels.csv').to_numpy()[:LIMIT,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylG0P08fYQxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_vocab(comments):\n",
        "  comments_split = [com.split() for com in comments]\n",
        "  vocab = dict()\n",
        "  pos = 0\n",
        "  txtidx = []\n",
        "  maxlength = 0\n",
        "\n",
        "  for comment in comments_split:\n",
        "      isent = []\n",
        "      maxlength = max(maxlength,len(comment))\n",
        "      for w in comment:\n",
        "          if w not in vocab:\n",
        "              vocab[w] = pos\n",
        "              pos +=1\n",
        "          isent.append(vocab[w])\n",
        "      txtidx.append(torch.LongTensor(list(set(isent))))\n",
        "  print(\"Number of words : \",len(vocab))\n",
        "  print(\"Maximum length of comment : \",maxlength)\n",
        "  print(\"Number of comments :\",len(comments_split))\n",
        "  print(txtidx[0])\n",
        "  vocab_size = len(vocab)\n",
        "\n",
        "  return txtidx,vocab_size\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8ehoEErYTOr",
        "colab_type": "code",
        "outputId": "76850a19-4f51-4ba3-d7d1-2ae1a08b3351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "txtidx,vocab_size = create_vocab(comments)\n",
        "labl = torch.from_numpy(labels).float().cuda()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words :  65553\n",
            "Maximum length of comment :  1403\n",
            "Number of comments : 20000\n",
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 37, 38, 39, 40])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw1s6riqYk4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CBOW_classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim,out_dim):\n",
        "        super(CBOW_classifier, self).__init__()\n",
        "        self.embeddings = nn.Embedding(\n",
        "                num_embeddings=vocab_size,\n",
        "                embedding_dim=embedding_dim)\n",
        "        self.lin = nn.Linear(embedding_dim,out_dim)\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        out = self.embeddings(inputs)\n",
        "        out = out.sum(dim=0)\n",
        "        return self.activation(self.lin(out))\n",
        "        #return self.lin(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKANo-WovKMu",
        "colab_type": "text"
      },
      "source": [
        "On essaie tout d'abord de classer les commentaires \"méchant\" et les commentaire \"gentil\" sans distinction de méchanceté, avec un simple classifieur.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWcPE_2uYnhN",
        "colab_type": "code",
        "outputId": "36916b3c-5bab-48a0-832f-53843215c230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "classifier = CBOW_classifier(vocab_size=vocab_size,embedding_dim=20,out_dim=1)\n",
        "loss_function = th.nn.BCELoss()\n",
        "classifier.cuda()\n",
        "optimizer = torch.optim.Adagrad(classifier.parameters(),lr=0.05)\n",
        "total = int(len(txtidx)*1/2)\n",
        "randomidx = list(range(total))\n",
        "preds = torch.zeros((total,6))\n",
        "classifier.train()\n",
        "batch_size = 1\n",
        "for epoch in range(10):\n",
        "    total_loss = torch.Tensor([0])\n",
        "    np.random.shuffle(randomidx)\n",
        "    classifier.zero_grad()\n",
        "    i = 0\n",
        "    acc = 0\n",
        "    for index in randomidx:\n",
        "        x = txtidx[index].cuda()\n",
        "        probs = classifier(x).cuda()\n",
        "        loss = loss_function(probs[0],torch.max(labl[index]))\n",
        "        loss.backward()\n",
        "        i +=1\n",
        "        if i%batch_size == 0:\n",
        "          optimizer.step()\n",
        "          classifier.zero_grad()\n",
        "        total_loss += loss.data\n",
        "        pred = probs>0.5\n",
        "        if pred.item() == max(labl[index]).item():\n",
        "          acc += 1\n",
        "        if i%2000 == 1999:\n",
        "          print(epoch,i+1,'/',len(randomidx),' : ',total_loss[0].item()/i)\n",
        "    print(epoch, total_loss[0]/len(randomidx),round(acc/i,3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 2000 / 10000  :  0.4343559719312781\n",
            "0 4000 / 10000  :  0.3632017318294417\n",
            "0 6000 / 10000  :  0.33406375427805673\n",
            "0 8000 / 10000  :  0.32792279576939304\n",
            "0 10000 / 10000  :  0.3175518235417292\n",
            "0 tensor(0.3175) 0.9\n",
            "1 2000 / 10000  :  0.2424696845493059\n",
            "1 4000 / 10000  :  0.21792053848423043\n",
            "1 6000 / 10000  :  0.20899524106882397\n",
            "1 8000 / 10000  :  0.20420274091878673\n",
            "1 10000 / 10000  :  0.20011937717209222\n",
            "1 tensor(0.2001) 0.927\n",
            "2 2000 / 10000  :  0.1463155741689204\n",
            "2 4000 / 10000  :  0.14654869161626344\n",
            "2 6000 / 10000  :  0.14349548370366416\n",
            "2 8000 / 10000  :  0.14318144138134453\n",
            "2 10000 / 10000  :  0.14533826429517951\n",
            "2 tensor(0.1453) 0.946\n",
            "3 2000 / 10000  :  0.10335751829772308\n",
            "3 4000 / 10000  :  0.10961448553056233\n",
            "3 6000 / 10000  :  0.10908363063765836\n",
            "3 8000 / 10000  :  0.10762389610224715\n",
            "3 10000 / 10000  :  0.10828446125862587\n",
            "3 tensor(0.1083) 0.961\n",
            "4 2000 / 10000  :  0.08698426514282531\n",
            "4 4000 / 10000  :  0.08157656937427717\n",
            "4 6000 / 10000  :  0.08177402532583555\n",
            "4 8000 / 10000  :  0.08368152647498907\n",
            "4 10000 / 10000  :  0.08314881781146864\n",
            "4 tensor(0.0831) 0.972\n",
            "5 2000 / 10000  :  0.062304532545813925\n",
            "5 4000 / 10000  :  0.06219845671867186\n",
            "5 6000 / 10000  :  0.06656477454901338\n",
            "5 8000 / 10000  :  0.06768554656978606\n",
            "5 10000 / 10000  :  0.06506439218140564\n",
            "5 tensor(0.0651) 0.98\n",
            "6 2000 / 10000  :  0.04579842335107984\n",
            "6 4000 / 10000  :  0.05393010087238607\n",
            "6 6000 / 10000  :  0.05056262632313719\n",
            "6 8000 / 10000  :  0.05145428105881399\n",
            "6 10000 / 10000  :  0.05173171736118924\n",
            "6 tensor(0.0517) 0.984\n",
            "7 2000 / 10000  :  0.041641265884407044\n",
            "7 4000 / 10000  :  0.042325644887784446\n",
            "7 6000 / 10000  :  0.042879689949952594\n",
            "7 8000 / 10000  :  0.04202816077717723\n",
            "7 10000 / 10000  :  0.0416669962894727\n",
            "7 tensor(0.0417) 0.989\n",
            "8 2000 / 10000  :  0.03152471545220853\n",
            "8 4000 / 10000  :  0.029905112691747157\n",
            "8 6000 / 10000  :  0.030929550168354882\n",
            "8 8000 / 10000  :  0.03281781148546889\n",
            "8 10000 / 10000  :  0.034079360084445946\n",
            "8 tensor(0.0341) 0.991\n",
            "9 2000 / 10000  :  0.028838502579536837\n",
            "9 4000 / 10000  :  0.03012111288930631\n",
            "9 6000 / 10000  :  0.029132408705487372\n",
            "9 8000 / 10000  :  0.02847024121423381\n",
            "9 10000 / 10000  :  0.028334605311117048\n",
            "9 tensor(0.0283) 0.993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gYHZvSrHe-6",
        "colab_type": "text"
      },
      "source": [
        "On obtien une accuracy de train de 99% ! Qu'en est il de la validation ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T67T_MloOJW",
        "colab_type": "code",
        "outputId": "23dcf249-49ac-42c0-fdd4-b714932cb8b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "def test_model(classifier,txtidx,lbl):\n",
        "  classifier.eval()\n",
        "  \n",
        "  M = np.zeros((2,2))\n",
        "  for i in range(10000):\n",
        "    probs = classifier(txtidx[i].cuda()).cuda()\n",
        "    if probs > 0.5:\n",
        "      pred = 1\n",
        "    else:\n",
        "      pred = 0\n",
        "    real = int(max(labl[i]))\n",
        "    M[real,pred] += 1\n",
        "  print(\"train : \", M)\n",
        "\n",
        "  M = np.zeros((2,2))\n",
        "  for i in range(10000,20000):\n",
        "    probs = classifier(txtidx[i].cuda()).cuda()\n",
        "    if probs > 0.5:\n",
        "      pred = 1\n",
        "    else:\n",
        "      pred = 0\n",
        "    real = int(max(labl[i]))\n",
        "    M[real,pred] += 1\n",
        "  print(\"val : \", M)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train :  [[8951.   19.]\n",
            " [  31.  999.]]\n",
            "val :  [[8673.  296.]\n",
            " [ 428.  603.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZBWId7rHw-E",
        "colab_type": "text"
      },
      "source": [
        "pas ouf, quasiment 50% d'erreur pour les commentaires méchants... on voudrait plutot l'inverse en réalité. Peut être que cela est du au fort taux de commentaire gentil dans le dataset ? Il y a en effet 90% de commentaire gentil, l'entrainement est biaisé. Voyons si l'ont peut faire mieux avec une distribution 50/50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPMwNP4GlQ5P",
        "colab_type": "code",
        "outputId": "71fd5e2b-e9a3-4aed-fb31-db996960bb8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "c = 0\n",
        "for i in range(20000):\n",
        "  if sum(labl[i]) == 0:\n",
        "    c += 1\n",
        "print(c/200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "89.695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTJ173NKIQi5",
        "colab_type": "text"
      },
      "source": [
        "# II. Augmenter le nombre de commentaire méchants\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s-UphnjkDZp",
        "colab_type": "code",
        "outputId": "38b78a40-1eec-41e2-b641-e29a67bcbf71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "source": [
        "!wget http://theo.delemazure.fr/perso/good_comments.csv\n",
        "!wget http://theo.delemazure.fr/perso/bad_comments.csv\n",
        "!wget http://theo.delemazure.fr/perso/bad_labels.csv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-25 09:31:46--  http://theo.delemazure.fr/perso/good_comments.csv\n",
            "Resolving theo.delemazure.fr (theo.delemazure.fr)... 217.160.0.80, 2001:8d8:100f:f000::267\n",
            "Connecting to theo.delemazure.fr (theo.delemazure.fr)|217.160.0.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56659184 (54M) [text/csv]\n",
            "Saving to: ‘good_comments.csv’\n",
            "\n",
            "good_comments.csv   100%[===================>]  54.03M  40.0MB/s    in 1.4s    \n",
            "\n",
            "2020-04-25 09:31:47 (40.0 MB/s) - ‘good_comments.csv’ saved [56659184/56659184]\n",
            "\n",
            "--2020-04-25 09:31:49--  http://theo.delemazure.fr/perso/bad_comments.csv\n",
            "Resolving theo.delemazure.fr (theo.delemazure.fr)... 217.160.0.80, 2001:8d8:100f:f000::267\n",
            "Connecting to theo.delemazure.fr (theo.delemazure.fr)|217.160.0.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4785381 (4.6M) [text/csv]\n",
            "Saving to: ‘bad_comments.csv’\n",
            "\n",
            "bad_comments.csv    100%[===================>]   4.56M  26.5MB/s    in 0.2s    \n",
            "\n",
            "2020-04-25 09:31:49 (26.5 MB/s) - ‘bad_comments.csv’ saved [4785381/4785381]\n",
            "\n",
            "--2020-04-25 09:31:51--  http://theo.delemazure.fr/perso/bad_labels.csv\n",
            "Resolving theo.delemazure.fr (theo.delemazure.fr)... 217.160.0.80, 2001:8d8:100f:f000::267\n",
            "Connecting to theo.delemazure.fr (theo.delemazure.fr)|217.160.0.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 297222 (290K) [text/csv]\n",
            "Saving to: ‘bad_labels.csv’\n",
            "\n",
            "bad_labels.csv      100%[===================>] 290.26K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-04-25 09:31:51 (3.77 MB/s) - ‘bad_labels.csv’ saved [297222/297222]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYNMmLnoQ1Er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT = 10000\n",
        "good_comments = pd.read_csv('good_comments.csv')[COMMENT].to_numpy()[:LIMIT]\n",
        "bad_comments  = pd.read_csv('bad_comments.csv')[COMMENT].to_numpy()[:LIMIT]\n",
        "\n",
        "comments_split = [com.split() for com in good_comments] + [com.split() for com in bad_comments]\n",
        "labels = np.array([0]*10000 + [1]*10000)\n",
        "\n",
        "randomidx = np.arange(LIMIT*2)\n",
        "np.random.shuffle(randomidx)\n",
        "comments_split = [comments_split[i] for i in randomidx]\n",
        "labels = [labels[i] for i in randomidx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp-sVl--RE1m",
        "colab_type": "code",
        "outputId": "0c9904f3-1cf8-4abc-db79-4c444e903a16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "vocab = dict()\n",
        "pos = 0\n",
        "txtidx = []\n",
        "maxlength = 0\n",
        "\n",
        "for comment in comments_split:\n",
        "    isent = []\n",
        "    maxlength = max(maxlength,len(comment))\n",
        "    for w in comment:\n",
        "        if w not in vocab:\n",
        "            vocab[w] = pos\n",
        "            pos +=1\n",
        "        isent.append(vocab[w])\n",
        "    txtidx.append(torch.LongTensor(list(set(isent))))\n",
        "\n",
        "print(\"Number of words : \",len(vocab))\n",
        "print(\"Maximum length of comment : \",maxlength)\n",
        "print(\"Number of comments :\",len(comments_split))\n",
        "print(txtidx[0])\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "labl = torch.tensor(labels).float().cuda()\n",
        "print(labl.shape)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words :  59255\n",
            "Maximum length of comment :  1403\n",
            "Number of comments : 20000\n",
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25])\n",
            "torch.Size([20000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p88IDCqGROzG",
        "colab_type": "code",
        "outputId": "31e41f58-8d53-4952-8eb4-49eef262b688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "classifier = CBOW_classifier(vocab_size=vocab_size,embedding_dim=20,out_dim=1)\n",
        "#loss_function = nn.MultiLabelSoftMarginLoss()\n",
        "loss_function = th.nn.BCELoss()\n",
        "classifier.cuda()\n",
        "optimizer = torch.optim.Adagrad(classifier.parameters(),lr=0.05)\n",
        "total = int(len(txtidx)*1/2)\n",
        "randomidx = list(range(total))\n",
        "preds = torch.zeros((total,6))\n",
        "classifier.train()\n",
        "batch_size = 1\n",
        "for epoch in range(10):\n",
        "    total_loss = torch.Tensor([0])\n",
        "    np.random.shuffle(randomidx)\n",
        "    classifier.zero_grad()\n",
        "    i = 0\n",
        "    acc = 0\n",
        "    for index in randomidx:\n",
        "        x = txtidx[index].cuda()\n",
        "        probs = classifier(x).cuda()\n",
        "        #loss = loss_function(probs[None,:], labl[index][None,:])\n",
        "        loss = loss_function(probs[0],labl[index].cuda())\n",
        "        loss.backward()\n",
        "        i +=1\n",
        "        if i%batch_size == 0:\n",
        "          optimizer.step()\n",
        "          classifier.zero_grad()\n",
        "        total_loss += loss.data\n",
        "        pred = probs>0.5\n",
        "        if pred.item() == labl[index].item():\n",
        "          acc += 1\n",
        "        if i%2000 == 1999:\n",
        "          print(epoch,i+1,'/',len(randomidx),' : ',total_loss[0].item()/i)\n",
        "    print(epoch, total_loss[0]/len(randomidx),round(acc/i,3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 2000 / 10000  :  0.6571886407070723\n",
            "0 4000 / 10000  :  0.5909046841788572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-dfee9fca19ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#loss = loss_function(probs[None,:], labl[index][None,:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrgAVFexR37L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.eval()\n",
        "\n",
        "M = np.zeros((2,2))\n",
        "for i in range(10000):\n",
        "  probs = classifier(txtidx[i].cuda()).cuda()\n",
        "  if probs > 0.5:\n",
        "    pred = 1\n",
        "  else:\n",
        "    pred = 0\n",
        "  real = int(labl[i])\n",
        "  M[real,pred] += 1\n",
        "print(\"train : \", M)\n",
        "\n",
        "\n",
        "M = np.zeros((2,2))\n",
        "for i in range(10000,20000):\n",
        "  probs = classifier(txtidx[i].cuda()).cuda()\n",
        "  if probs > 0.5:\n",
        "    pred = 1\n",
        "  else:\n",
        "    pred = 0\n",
        "  real = int(labl[i])\n",
        "  M[real,pred] += 1\n",
        "print(\"val : \", M)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqH5tjLWUdhc",
        "colab_type": "text"
      },
      "source": [
        "ça marche déjà Vachement mieux ! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svcUt5jkWUOe",
        "colab_type": "text"
      },
      "source": [
        "# III. Meilleur classifieur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv6Y_d_JWYvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class MLP_classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim,out_dim, hidden_dim = 10):\n",
        "        super(MLP_classifier, self).__init__()\n",
        "        self.embeddings = nn.Embedding(\n",
        "                num_embeddings=vocab_size,\n",
        "                embedding_dim=embedding_dim)\n",
        "        self.couches = []\n",
        "        self.hidden = nn.Linear(embedding_dim,hidden_dim)\n",
        "        \n",
        "        self.fin = nn.Linear(hidden_dim,out_dim)\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        out = self.embeddings(inputs)\n",
        "        out = out.sum(dim=0)\n",
        "        out = F.relu(self.hidden(out))\n",
        "\n",
        "        return self.activation(self.fin(out))\n",
        "        #return self.lin(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xqw0oVsSXIZm",
        "outputId": "e7c0e235-9429-4ebd-ffc9-7aa22fb62948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "classifier = MLP_classifier(vocab_size=vocab_size,embedding_dim=25,out_dim=1,hidden_dim=10)\n",
        "#loss_function = nn.MultiLabelSoftMarginLoss()\n",
        "loss_function = th.nn.BCELoss()\n",
        "classifier.cuda()\n",
        "optimizer = torch.optim.Adagrad(classifier.parameters(),lr=0.05)\n",
        "total = int(len(txtidx)*1/2)\n",
        "randomidx = list(range(total))\n",
        "preds = torch.zeros((total,6))\n",
        "classifier.train()\n",
        "batch_size = 1\n",
        "for epoch in range(10):\n",
        "    total_loss = torch.Tensor([0])\n",
        "    np.random.shuffle(randomidx)\n",
        "    classifier.zero_grad()\n",
        "    i = 0\n",
        "    acc = 0\n",
        "    for index in randomidx:\n",
        "        x = txtidx[index].cuda()\n",
        "        probs = classifier(x).cuda()\n",
        "        #loss = loss_function(probs[None,:], labl[index][None,:])\n",
        "        loss = loss_function(probs[0],labl[index].cuda())\n",
        "        loss.backward()\n",
        "        i +=1\n",
        "        if i%batch_size == 0:\n",
        "          optimizer.step()\n",
        "          classifier.zero_grad()\n",
        "        total_loss += loss.data\n",
        "        pred = probs>0.5\n",
        "        if pred.item() == labl[index].item():\n",
        "          acc += 1\n",
        "        if i%2000 == 1999:\n",
        "          print(epoch,i+1,'/',len(randomidx),' : ',total_loss[0].item()/i)\n",
        "    print(epoch, total_loss[0]/len(randomidx),round(acc/i,3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 2000 / 10000  :  0.5763937877141696\n",
            "0 4000 / 10000  :  0.5367806184944673\n",
            "0 6000 / 10000  :  0.5043264860549675\n",
            "0 8000 / 10000  :  0.47788728107615014\n",
            "0 10000 / 10000  :  0.46585640009313434\n",
            "0 tensor(0.4658) 0.778\n",
            "1 2000 / 10000  :  0.308221066099456\n",
            "1 4000 / 10000  :  0.29060115370639533\n",
            "1 6000 / 10000  :  0.2888434083089369\n",
            "1 8000 / 10000  :  0.28218026154636516\n",
            "1 10000 / 10000  :  0.28086863862167466\n",
            "1 tensor(0.2809) 0.882\n",
            "2 2000 / 10000  :  0.20263487151290488\n",
            "2 4000 / 10000  :  0.19914002548488685\n",
            "2 6000 / 10000  :  0.1985384201403359\n",
            "2 8000 / 10000  :  0.1949171411318993\n",
            "2 10000 / 10000  :  0.19141309882941418\n",
            "2 tensor(0.1914) 0.923\n",
            "3 2000 / 10000  :  0.1288643284044366\n",
            "3 4000 / 10000  :  0.132069470614724\n",
            "3 6000 / 10000  :  0.12888761082576264\n",
            "3 8000 / 10000  :  0.13145040652054163\n",
            "3 10000 / 10000  :  0.13177742334780354\n",
            "3 tensor(0.1318) 0.951\n",
            "4 2000 / 10000  :  0.08138968623716154\n",
            "4 4000 / 10000  :  0.08728605796468648\n",
            "4 6000 / 10000  :  0.08739744994934051\n",
            "4 8000 / 10000  :  0.08642255361265862\n",
            "4 10000 / 10000  :  0.08914347245271402\n",
            "4 tensor(0.0891) 0.968\n",
            "5 2000 / 10000  :  0.06779260907309123\n",
            "5 4000 / 10000  :  0.05914643944189172\n",
            "5 6000 / 10000  :  0.0583579776723855\n",
            "5 8000 / 10000  :  0.06217397429195251\n",
            "5 10000 / 10000  :  0.061861941809415316\n",
            "5 tensor(0.0619) 0.979\n",
            "6 2000 / 10000  :  0.050396501809254236\n",
            "6 4000 / 10000  :  0.04648558227203285\n",
            "6 6000 / 10000  :  0.04783514639321397\n",
            "6 8000 / 10000  :  0.04580567917058968\n",
            "6 10000 / 10000  :  0.04276807380445076\n",
            "6 tensor(0.0428) 0.986\n",
            "7 2000 / 10000  :  0.028745510984862548\n",
            "7 4000 / 10000  :  0.02926949007149248\n",
            "7 6000 / 10000  :  0.030802311351208273\n",
            "7 8000 / 10000  :  0.030126555202334863\n",
            "7 10000 / 10000  :  0.030587110224694344\n",
            "7 tensor(0.0306) 0.991\n",
            "8 2000 / 10000  :  0.018117627005030834\n",
            "8 4000 / 10000  :  0.020506597215099672\n",
            "8 6000 / 10000  :  0.021138109352453926\n",
            "8 8000 / 10000  :  0.021024085682829496\n",
            "8 10000 / 10000  :  0.022121364968528102\n",
            "8 tensor(0.0221) 0.993\n",
            "9 2000 / 10000  :  0.013590885675686965\n",
            "9 4000 / 10000  :  0.013816501534441228\n",
            "9 6000 / 10000  :  0.014487067984231095\n",
            "9 8000 / 10000  :  0.015205706636791513\n",
            "9 10000 / 10000  :  0.016132417685127888\n",
            "9 tensor(0.0161) 0.996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp1f1dJlXEOb",
        "colab_type": "code",
        "outputId": "fac5a15f-adc4-48e7-b83f-333439d51438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "classifier.eval()\n",
        "\n",
        "M = np.zeros((2,2))\n",
        "for i in range(10000):\n",
        "  probs = classifier(txtidx[i].cuda()).cuda()\n",
        "  if probs > 0.5:\n",
        "    pred = 1\n",
        "  else:\n",
        "    pred = 0\n",
        "  real = int(labl[i])\n",
        "  M[real,pred] += 1\n",
        "print(\"train : \", M)\n",
        "\n",
        "\n",
        "M = np.zeros((2,2))\n",
        "for i in range(10000,20000):\n",
        "  probs = classifier(txtidx[i].cuda()).cuda()\n",
        "  if probs > 0.5:\n",
        "    pred = 1\n",
        "  else:\n",
        "    pred = 0\n",
        "  real = int(labl[i])\n",
        "  M[real,pred] += 1\n",
        "print(\"val : \", M)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train :  [[5011.   16.]\n",
            " [  14. 4959.]]\n",
            "val :  [[4229.  744.]\n",
            " [ 803. 4224.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWfP0ZOlWZdX",
        "colab_type": "text"
      },
      "source": [
        "# IV. Prédire la cause de méchanceté\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9m_ru2nWh3D",
        "colab_type": "code",
        "outputId": "7ad8ddf2-7cc6-49bc-8019-4a96b50c2809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "bad_labels = pd.read_csv('bad_labels.csv').to_numpy()[:LIMIT,1:]\n",
        "labels = np.concatenate([np.zeros((LIMIT,6)),bad_labels],0)\n",
        "comments_split = [com.split() for com in good_comments] + [com.split() for com in bad_comments]\n",
        "\n",
        "randomidx = np.arange(LIMIT*2)\n",
        "np.random.shuffle(randomidx)\n",
        "comments_split = [comments_split[i] for i in randomidx]\n",
        "labels = [labels[i] for i in randomidx]\n",
        "\n",
        "vocab = dict()\n",
        "pos = 0\n",
        "txtidx = []\n",
        "maxlength = 0\n",
        "\n",
        "for comment in comments_split:\n",
        "    isent = []\n",
        "    maxlength = max(maxlength,len(comment))\n",
        "    for w in comment:\n",
        "        if w not in vocab:\n",
        "            vocab[w] = pos\n",
        "            pos +=1\n",
        "        isent.append(vocab[w])\n",
        "    txtidx.append(torch.LongTensor(list(set(isent))))\n",
        "\n",
        "print(\"Number of words : \",len(vocab))\n",
        "print(\"Maximum length of comment : \",maxlength)\n",
        "print(\"Number of comments :\",len(comments_split))\n",
        "print(txtidx[0])\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "labl = torch.tensor(labels).float().cuda()\n",
        "print(labl.shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words :  59255\n",
            "Maximum length of comment :  1403\n",
            "Number of comments : 20000\n",
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n",
            "torch.Size([20000, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPm6ZQxkdRpG",
        "colab_type": "code",
        "outputId": "9692a387-9d1a-4d36-9e55-cb61b2637dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        }
      },
      "source": [
        "classifier = CBOW_classifier(vocab_size=vocab_size,embedding_dim=25,out_dim=6)\n",
        "loss_function = nn.MultiLabelSoftMarginLoss()\n",
        "#loss_function = th.nn.BCELoss()\n",
        "classifier.cuda()\n",
        "optimizer = torch.optim.Adagrad(classifier.parameters(),lr=0.01)\n",
        "total = int(len(txtidx)*1/2)\n",
        "randomidx = list(range(total))\n",
        "preds = torch.zeros((total,6))\n",
        "classifier.train()\n",
        "batch_size = 1\n",
        "for epoch in range(10):\n",
        "    total_loss = torch.Tensor([0])\n",
        "    np.random.shuffle(randomidx)\n",
        "    classifier.zero_grad()\n",
        "    i = 0\n",
        "    acc = 0\n",
        "    for index in randomidx:\n",
        "        x = txtidx[index].cuda()\n",
        "        probs = classifier(x).cuda()\n",
        "        loss = loss_function(probs[None,:], labl[index][None,:].cuda())\n",
        "        #loss = loss_function(probs[0],labl[index].cuda())\n",
        "        loss.backward()\n",
        "        i +=1\n",
        "        if i%batch_size == 0:\n",
        "          optimizer.step()\n",
        "          classifier.zero_grad()\n",
        "        total_loss += loss.data\n",
        "        pred = probs>0.5\n",
        "        if i%2000 == 1999:\n",
        "          print(epoch,i+1,'/',len(randomidx),' : ',total_loss[0].item()/i)\n",
        "    print(epoch, total_loss[0]/len(randomidx))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 2000 / 10000  :  0.7270653148840045\n",
            "0 4000 / 10000  :  0.7167950434874344\n",
            "0 6000 / 10000  :  0.7119213879396566\n",
            "0 8000 / 10000  :  0.7090616551678335\n",
            "0 10000 / 10000  :  0.7066899072719772\n",
            "0 tensor(0.7067)\n",
            "1 2000 / 10000  :  0.6977448074623249\n",
            "1 4000 / 10000  :  0.6963651923723119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-f0ff3a2d9513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#loss = loss_function(probs[0],labl[index].cuda())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6yNY0RMeWEI",
        "colab_type": "code",
        "outputId": "11ffe859-036d-4d05-f045-ef670eab6243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "classifier.eval()\n",
        "\n",
        "j = 0\n",
        "M = np.zeros((2,2))\n",
        "for i in range(10000):\n",
        "  probs = classifier(txtidx[i].cuda()).cuda()\n",
        "  if probs[j] > 0.5:\n",
        "    pred = 1\n",
        "  else:\n",
        "    pred = 0\n",
        "  real = int(labl[i,j])\n",
        "  M[real,pred] += 1\n",
        "print(\"train : \", M)\n",
        "\n",
        "\n",
        "M = np.zeros((2,2))\n",
        "for i in range(10000,20000):\n",
        "  probs = classifier(txtidx[i].cuda()).cuda()\n",
        "  if probs[j] > 0.5:\n",
        "    pred = 1\n",
        "  else:\n",
        "    pred = 0\n",
        "  real = int(labl[i,j])\n",
        "  M[real,pred] += 1\n",
        "print(\"val : \", M)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train :  [[9.585e+03 0.000e+00]\n",
            " [4.130e+02 2.000e+00]]\n",
            "val :  [[9572.   10.]\n",
            " [ 418.    0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQYW6LFYbAnH",
        "colab_type": "text"
      },
      "source": [
        "## V. Utiliser les embeddings FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGnccoMObC1u",
        "colab_type": "code",
        "outputId": "b35bf97f-7cd3-4d1f-e12d-a8f46ee64bd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!unzip wiki-news-300d-1M.vec.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-24 09:25:05--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 2606:4700:10::6816:4a8e, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  5.45MB/s    in 3m 2s   \n",
            "\n",
            "2020-04-24 09:28:07 (3.58 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n",
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBUDZVdugTVg",
        "colab_type": "code",
        "outputId": "de9829a3-fbbe-4001-9e2a-89a991598904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import gensim\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec')\n",
        "weights = torch.FloatTensor(model.vectors) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-2fadd31392ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wiki-news-300d-1M.vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get embeddings for index 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'weight' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha3EiqXxmfCY",
        "colab_type": "code",
        "outputId": "11a15459-6ce6-419a-d345-d16e751c8e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "embedding = nn.Embedding.from_pretrained(weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-b05d0a91966e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Word2VecKeyedVectors' object has no attribute 'words'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrLK2TM1iGu2",
        "colab_type": "code",
        "outputId": "6cccbc44-b384-408d-8b1d-9348257254ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "word_vectors = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHObh_ebm_Bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT = 10000\n",
        "good_comments = pd.read_csv('good_comments.csv')[COMMENT].to_numpy()[:LIMIT]\n",
        "bad_comments  = pd.read_csv('bad_comments.csv')[COMMENT].to_numpy()[:LIMIT]\n",
        "\n",
        "comments_split = [com.split() for com in good_comments] + [com.split() for com in bad_comments]\n",
        "labels = np.array([0]*10000 + [1]*10000)\n",
        "\n",
        "randomidx = np.arange(LIMIT*2)\n",
        "np.random.shuffle(randomidx)\n",
        "comments_split = [comments_split[i] for i in randomidx]\n",
        "labels = [labels[i] for i in randomidx]\n",
        "labl = torch.tensor(labels).float().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUiRcDlUnuiF",
        "colab_type": "code",
        "outputId": "59abae3f-6fc9-401b-c332-8872bb21dcfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(comments_split[15])\n",
        "print(word_vectors[comments_split[15]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['get', 'a', 'proper', 'job', 'daft', 'cunt']\n",
            "[[ 1.4433e-01  4.3951e-01  5.8324e-01 -7.4477e-01 -4.9797e-01  8.6928e-02\n",
            "  -2.9798e-01  3.9964e-01  1.4083e-01 -3.6578e-01  3.3322e-01  4.7181e-01\n",
            "   1.9960e-01  1.8278e-01  1.7176e-01 -3.4297e-01  4.2520e-02  3.9309e-01\n",
            "  -6.6272e-01  6.2738e-01  2.2845e-01  4.4657e-01  1.1174e-01 -4.1396e-01\n",
            "   7.9795e-02  7.8823e-02 -2.6135e-01 -8.0966e-01  5.2807e-01 -4.7327e-01\n",
            "   5.5901e-02  8.5753e-01  1.9722e-01  3.0782e-01  3.9039e-01  3.1804e-01\n",
            "  -5.3604e-01  1.8350e-01  8.1918e-02  2.7753e-01 -2.5792e-01 -3.7158e-01\n",
            "  -2.2150e-01 -1.0916e+00 -5.2179e-01  1.2665e-01 -4.8591e-01 -2.6716e-01\n",
            "   3.7119e-01 -1.0525e+00 -3.0202e-01 -1.6279e-01 -3.2528e-01  9.5493e-01\n",
            "   1.4915e-01 -2.4934e+00  2.7505e-01  1.6308e-01  1.8972e+00  2.1172e-01\n",
            "   1.0776e-01  1.1318e+00 -8.5962e-01  6.0199e-02  8.3713e-01  3.0006e-02\n",
            "   5.9344e-01  4.2821e-01 -1.3722e-01 -4.9128e-01  4.3155e-03 -5.1829e-01\n",
            "  -5.9878e-02 -5.8476e-01  6.2621e-02  3.1269e-01 -5.2613e-01 -3.5209e-01\n",
            "  -4.9959e-01 -1.3117e-01  6.2349e-01 -9.2936e-02 -9.2224e-01 -3.2487e-01\n",
            "  -1.8286e+00 -1.2840e-01  5.0507e-01 -3.4628e-02 -7.9806e-01 -4.9739e-01\n",
            "  -9.6325e-02 -1.7695e-01 -3.6351e-02 -7.5977e-01 -4.9938e-01 -2.0278e-01\n",
            "   3.4232e-01  5.0134e-01  4.9536e-01  4.9920e-01]\n",
            " [-2.7086e-01  4.4006e-02 -2.0260e-02 -1.7395e-01  6.4440e-01  7.1213e-01\n",
            "   3.5510e-01  4.7138e-01 -2.9637e-01  5.4427e-01 -7.2294e-01 -4.7612e-03\n",
            "   4.0611e-02  4.3236e-02  2.9729e-01  1.0725e-01  4.0156e-01 -5.3662e-01\n",
            "   3.3382e-02  6.7396e-02  6.4556e-01 -8.5523e-02  1.4103e-01  9.4539e-02\n",
            "   7.4947e-01 -1.9400e-01 -6.8739e-01 -4.1741e-01 -2.2807e-01  1.2000e-01\n",
            "  -4.8999e-01  8.0945e-01  4.5138e-02 -1.1898e-01  2.0161e-01  3.9276e-01\n",
            "  -2.0121e-01  3.1354e-01  7.5304e-01  2.5907e-01 -1.1566e-01 -2.9319e-02\n",
            "   9.3499e-01 -3.6067e-01  5.2420e-01  2.3706e-01  5.2715e-01  2.2869e-01\n",
            "  -5.1958e-01 -7.9349e-01 -2.0368e-01 -5.0187e-01  1.8748e-01  9.4282e-01\n",
            "  -4.4834e-01 -3.6792e+00  4.4183e-02 -2.6751e-01  2.1997e+00  2.4100e-01\n",
            "  -3.3425e-02  6.9553e-01 -6.4472e-01 -7.2277e-03  8.9575e-01  2.0015e-01\n",
            "   4.6493e-01  6.1933e-01 -1.0660e-01  8.6910e-02 -4.6230e-01  1.8262e-01\n",
            "  -1.5849e-01  2.0791e-02  1.9373e-01  6.3426e-02 -3.1673e-01 -4.8177e-01\n",
            "  -1.3848e+00  1.3669e-01  9.6859e-01  4.9965e-02 -2.7380e-01 -3.5686e-02\n",
            "  -1.0577e+00 -2.4467e-01  9.0366e-01 -1.2442e-01  8.0776e-02 -8.3401e-01\n",
            "   5.7201e-01  8.8945e-02 -4.2532e-01 -1.8253e-02 -7.9995e-02 -2.8581e-01\n",
            "  -1.0890e-02 -4.9230e-01  6.3687e-01  2.3642e-01]\n",
            " [ 3.7213e-01 -1.7986e-01  2.0448e-01  5.5804e-01 -5.1843e-01  3.6125e-01\n",
            "  -3.3818e-01  4.9792e-01  1.3616e-01  3.7861e-01 -1.3602e-01  1.1461e-01\n",
            "   7.0294e-01  4.4600e-01  6.4499e-02 -4.8989e-01  4.9771e-01 -2.0459e-01\n",
            "  -1.4172e-01 -1.3551e-01 -5.4810e-01 -3.7206e-01 -9.4805e-02 -3.9534e-01\n",
            "  -5.1372e-01 -2.3266e-01 -1.7265e-02 -5.7985e-01 -2.2243e-01 -2.1688e-01\n",
            "  -2.1292e-01 -1.5684e-01  1.2595e-01  4.8888e-02  6.2450e-01 -2.9779e-01\n",
            "  -5.1002e-02  2.5791e-02 -2.1295e-01 -2.1206e-01  2.8491e-02 -1.1755e-01\n",
            "   4.6536e-01 -3.2494e-01 -2.2755e-01 -1.8975e-01  2.4998e-03 -1.4602e-01\n",
            "   9.3233e-02 -6.8987e-01  5.2448e-01  3.6940e-01 -2.9341e-01  6.8698e-01\n",
            "  -1.3822e-01 -1.4307e+00  7.2343e-01 -3.4736e-01  1.7401e+00 -4.2586e-01\n",
            "  -1.2719e-01  1.1713e-01 -4.2049e-01  1.4608e-01  1.4096e+00 -5.7830e-02\n",
            "  -4.5282e-01 -2.2897e-01 -3.2732e-02 -5.2954e-01 -8.2705e-01 -5.5367e-02\n",
            "   9.0573e-01 -1.2225e-01  1.1029e+00  5.5138e-01 -6.9013e-01 -2.1012e-01\n",
            "  -2.3575e-01 -3.8461e-01  3.7032e-01  1.9659e-02 -5.0839e-01  1.6880e-01\n",
            "  -1.0749e+00  7.6036e-01  1.5754e-01 -9.9791e-02  4.9115e-03  1.7473e-01\n",
            "   3.1259e-02 -4.2890e-01  2.1716e-01  1.2100e-01  2.4260e-01  2.6409e-01\n",
            "  -1.2921e-01 -3.4031e-01  4.0686e-01  4.7072e-01]\n",
            " [ 2.2115e-01  2.7844e-02 -5.3894e-02 -4.7618e-01 -3.6360e-01 -5.1352e-01\n",
            "  -2.6740e-01  1.7786e-01  8.0002e-02  3.2405e-01  5.4443e-02 -4.4604e-01\n",
            "   2.9408e-01 -1.3636e-01 -5.8729e-02 -5.1118e-01  2.2774e-01  1.6583e-01\n",
            "   1.7965e-01  8.3305e-01 -4.0784e-01  4.3205e-01 -5.9220e-01 -3.3962e-01\n",
            "   7.4495e-02 -7.8615e-01 -3.4714e-01 -7.3778e-01 -2.0165e-01 -3.7517e-01\n",
            "  -5.1120e-01  4.3905e-01  1.5289e-01 -5.3582e-01 -6.3758e-01  4.3056e-01\n",
            "  -1.0624e+00  3.4708e-02  2.9883e-01 -3.4365e-01 -3.6841e-01 -1.8023e-01\n",
            "   3.7373e-01 -2.3811e-02 -3.5930e-01  6.7622e-01 -1.4587e-01 -7.4340e-01\n",
            "   2.0008e-03 -1.2319e+00  2.2214e-01 -8.4533e-01 -5.5439e-01  1.6319e+00\n",
            "   2.2335e-01 -2.2183e+00  4.7548e-01 -3.9548e-01  1.4745e+00  1.1082e-01\n",
            "  -1.4890e-01  6.0955e-02 -3.3584e-01 -2.7165e-01  7.5480e-01 -1.1876e-01\n",
            "   8.1228e-01  6.2684e-02  2.5561e-01  2.7192e-01  1.8614e-01  3.9781e-02\n",
            "  -6.3905e-01 -4.7369e-01  4.9374e-01  2.6515e-01 -5.1318e-01  2.8599e-01\n",
            "  -2.9260e-01 -8.2741e-02  5.2519e-01 -1.2291e-01 -4.6558e-01 -4.3100e-01\n",
            "  -1.5716e+00 -6.5427e-01  4.7403e-01 -5.1794e-02 -5.5861e-01 -9.9539e-01\n",
            "   2.4111e-01 -3.4781e-02  6.2401e-01  3.4960e-01 -1.6383e-01  3.2218e-01\n",
            "   2.2630e-01  5.2428e-01  6.7877e-01  3.5839e-01]\n",
            " [-4.5048e-01 -2.0422e-01  1.0536e+00 -4.1892e-01 -4.8788e-01  3.6925e-02\n",
            "   1.7262e-01 -6.0776e-01 -3.0252e-01  2.1253e-01  4.9919e-01  7.9363e-02\n",
            "   2.4950e-01 -4.3513e-01 -1.9366e-01 -4.1396e-01  3.3946e-01  8.3190e-02\n",
            "   4.0259e-01 -8.6966e-02  7.3715e-01 -2.8237e-01  9.0442e-03  1.0611e-02\n",
            "  -9.4849e-01  5.6205e-01  2.4761e-01  2.3845e-01 -8.7557e-02  5.1830e-02\n",
            "  -3.7920e-01  7.9420e-01 -2.9198e-02 -4.5899e-01  1.9324e-01  3.6329e-01\n",
            "   1.0071e-01 -1.7395e-01  2.6955e-01 -3.6469e-01  2.2857e-01  5.4766e-01\n",
            "  -1.2181e-01  1.4327e-01 -8.9559e-01  1.1644e+00 -6.9483e-01 -7.1906e-01\n",
            "  -3.3728e-03 -8.7996e-02 -2.5366e-01 -7.4930e-01 -1.4566e+00 -7.5934e-01\n",
            "  -4.8191e-01 -1.9512e-01 -4.4819e-01  4.1285e-01 -2.1477e-01 -2.3829e-01\n",
            "   5.7233e-01  3.0985e-01 -4.1151e-01  3.1226e-01 -3.7538e-01 -9.2341e-01\n",
            "   5.6294e-01  4.6957e-01  4.1519e-01 -5.5730e-01 -9.1847e-02 -4.1760e-02\n",
            "  -4.1290e-01  2.4515e-01 -1.1781e+00 -7.9493e-01 -4.2417e-01 -5.8755e-01\n",
            "  -1.4650e-01  2.1957e-01 -6.0543e-01 -4.3483e-01  2.2901e-01  3.1042e-01\n",
            "  -5.7049e-01 -6.4579e-01  4.7845e-01 -1.7908e-01 -5.9358e-01  2.6432e-01\n",
            "   5.8319e-01 -2.0708e-01 -8.0100e-01  6.3081e-01  6.7613e-01 -3.3047e-01\n",
            "  -1.0160e+00  1.2379e-01 -4.6088e-01  3.7646e-01]\n",
            " [ 3.3786e-01 -1.5487e-01  1.9885e-01 -8.7887e-01 -5.3653e-01  2.5236e-02\n",
            "   2.5658e-01  1.6883e-01  2.4274e-01 -1.8930e-01 -7.4675e-01  2.6281e-01\n",
            "   1.6763e-01  2.5766e-02 -1.9581e-01 -2.8986e-01 -1.1431e-01 -1.4621e-01\n",
            "   2.4068e-01  8.1126e-01 -7.9618e-02 -2.3710e-02 -6.9977e-01  2.0524e-01\n",
            "   3.8370e-03  8.9232e-01  1.7568e-02 -1.4764e-01  3.9513e-01  6.1435e-02\n",
            "   6.6902e-01 -1.4518e-01  2.3075e-01  1.0166e-01  3.1118e-01 -4.7249e-01\n",
            "  -6.9168e-01  3.4953e-01  5.6509e-01 -2.5039e-01  3.6109e-01  5.0528e-01\n",
            "  -1.0426e-01  1.9904e-01 -6.5852e-01 -3.8750e-02  1.1868e-01  4.6087e-01\n",
            "   6.7093e-02  4.4767e-01 -6.2674e-01  2.9362e-01  2.6083e-02  1.7589e-02\n",
            "  -9.8638e-01  2.2622e-01  5.2264e-01  1.3564e-01 -4.5149e-01  1.2709e-01\n",
            "   1.3213e-01 -1.6856e-01 -4.3399e-01 -2.2540e-01  8.4927e-01 -1.7699e-01\n",
            "   2.3963e-01 -6.1373e-01  2.3447e-01 -5.9636e-01 -1.2559e-02  7.0573e-01\n",
            "   6.4924e-01  3.8428e-01 -5.2411e-01 -1.7696e-01 -3.4175e-01  4.6840e-01\n",
            "   7.0364e-01  5.0397e-01 -4.1632e-01 -7.1233e-01  2.8044e-01  2.0297e-01\n",
            "  -8.6194e-02 -3.0646e-01  6.9632e-01 -2.4441e-01  2.8642e-01  7.4832e-01\n",
            "  -4.9863e-01  4.0311e-01  5.6031e-02 -4.2496e-02  7.9044e-01 -5.1060e-01\n",
            "   9.1598e-02  3.0266e-01 -5.6007e-01 -1.4749e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nob60Q9AnXfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP_classifier_2(nn.Module):\n",
        "\n",
        "    def __init__(self,embedding_dim,hidden_dim,out_dim):\n",
        "        super(MLP_classifier_2, self).__init__()\n",
        "        self.hidden = nn.Linear(embedding_dim,hidden_dim)\n",
        "        self.lin = nn.Linear(hidden_dim,out_dim)\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        out = inputs.sum(dim=0)\n",
        "        out = F.relu(self.hidden(out))\n",
        "        return self.activation(self.lin(out))\n",
        "        #return self.lin(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0wc7eFyoTPd",
        "colab_type": "code",
        "outputId": "cfbc9213-df19-4c30-a07c-5ae4fc7ea64c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "classifier = MLP_classifier_2(100,hidden_dim=20,out_dim=1)\n",
        "#loss_function = nn.MultiLabelSoftMarginLoss()\n",
        "loss_function = th.nn.BCELoss()\n",
        "classifier.cuda()\n",
        "optimizer = torch.optim.Adagrad(classifier.parameters(),lr=0.01)\n",
        "total = int(len(txtidx)*1/2)\n",
        "randomidx = list(range(total))\n",
        "preds = torch.zeros((total,6))\n",
        "classifier.train()\n",
        "batch_size = 1\n",
        "for epoch in range(10):\n",
        "    total_loss = torch.Tensor([0])\n",
        "    np.random.shuffle(randomidx)\n",
        "    classifier.zero_grad()\n",
        "    i = 0\n",
        "    acc = 0\n",
        "    for index in randomidx:\n",
        "        x = comments_split[index]\n",
        "        print(x)\n",
        "        probs = classifier(th.Tensor(word_vectors[x]).cuda()).cuda()\n",
        "        #loss = loss_function(probs[None,:], labl[index][None,:])\n",
        "        loss = loss_function(probs[0],labl[index].cuda())\n",
        "        loss.backward()\n",
        "        i +=1\n",
        "        if i%batch_size == 0:\n",
        "          optimizer.step()\n",
        "          classifier.zero_grad()\n",
        "        total_loss += loss.data\n",
        "        pred = probs>0.5\n",
        "        if pred.item() == labl[index].item():\n",
        "          acc += 1\n",
        "        if i%2000 == 1999:\n",
        "          print(epoch,i+1,'/',len(randomidx),' : ',total_loss[0].item()/i)\n",
        "    print(epoch, total_loss[0]/len(randomidx),round(acc/i,3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['k', 'what', 'the', 'fuck', 'man', 'why', 'did', 'you', 'add', 'a', 'new', 'source', 'the', 'source', 'given', 'was', 'invalidmeaning', 'that', 'genre', \"can't\", 'be', 'listed', \"anywaydon't\", 'see', 'why', 'that', 'was', 'cleared', 'as', 'a', 'source', 'from', 'the', 'getgo', 'so', 'in', 'that', 'casehow', 'how', 'does', 'that', 'differ', 'from', 'me', 'adding', 'a', 'deathcore', 'genre', 'just', 'get', 'rid', 'of', 'the', 'fucking', 'melodic', 'death', 'metal', 'seciton', 'of', 'it', \"it's\", 'pretty', 'muchfucked', 'up']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-8ea14605a1d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomments_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m#loss = loss_function(probs[None,:], labl[index][None,:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'invalidmeaning' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-OudiJJpr-T",
        "colab_type": "text"
      },
      "source": [
        "# VI. Conv1D "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4E8mRcEKyv4",
        "colab_type": "code",
        "outputId": "36825627-2a28-4208-d465-5fb08543040f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "h1 = 4 # dimension of embeddings, the input size for convolution\n",
        "h2 = 2 # output dimension (filter size) for the convolution\n",
        "embLayer = th.nn.Embedding(num_embeddings=vocab_size, embedding_dim=h1)\n",
        "print(txtidx[2])\n",
        "embs = embLayer(txtidx[2])\n",
        "print(len(txtidx[2]))\n",
        "print(embs.shape)\n",
        "\n",
        "conv1 = th.nn.Conv1d(in_channels=4,out_channels=2,kernel_size=3,padding=1)\n",
        "tmp=embs.view(1,4,-1)\n",
        "res = conv1(tmp)\n",
        "print(\"embs : \",embs.shape)\n",
        "print(\"tmp  : \",tmp.shape)\n",
        "print(\"conv : \",res.shape)\n",
        "\n",
        "m = th.nn.MaxPool1d(res.shape[-1])\n",
        "res = m(res)\n",
        "res = res.view(h2)\n",
        "print(\"mp : \",res.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0, 12, 16, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n",
            "        40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
            "        58, 59, 60, 61, 62, 63, 64])\n",
            "43\n",
            "torch.Size([43, 4])\n",
            "embs :  torch.Size([43, 4])\n",
            "tmp  :  torch.Size([1, 4, 43])\n",
            "conv :  torch.Size([1, 2, 43])\n",
            "mp :  torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKq8_jSuptsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv1D_classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim,out_dim, feat_size=10, kernel_size=3):\n",
        "        super(Conv1D_classifier, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embeddings = nn.Embedding(\n",
        "                num_embeddings=vocab_size,\n",
        "                embedding_dim=embedding_dim)\n",
        "        \n",
        "        self.conv = nn.Conv1d(embedding_dim,feat_size,kernel_size,padding=1)\n",
        "        \n",
        "        self.lin = nn.Linear(feat_size,out_dim)      \n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embs = self.embeddings(inputs)\n",
        "        tmp=embs.view(1,self.embedding_dim,-1)\n",
        "        tmp = self.conv(tmp)\n",
        "        out = nn.MaxPool1d(tmp.shape[-1])(tmp)\n",
        "        out = out.view(out.shape[1])\n",
        "\n",
        "        return self.activation(self.lin(out))\n",
        "        #return self.lin(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IvOx4YkvgTr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "outputId": "ba895929-5239-4c22-b95b-93c02b5823c5"
      },
      "source": [
        "classifier = Conv1D_classifier(vocab_size=vocab_size,embedding_dim=40,out_dim=1,feat_size=20)\n",
        "#loss_function = nn.MultiLabelSoftMarginLoss()\n",
        "loss_function = th.nn.BCELoss()\n",
        "classifier.cuda()\n",
        "optimizer = torch.optim.Adagrad(classifier.parameters(),lr=0.1)\n",
        "total = int(len(txtidx)*1/2)\n",
        "randomidx = list(range(total))\n",
        "preds = torch.zeros((total,6))\n",
        "classifier.train()\n",
        "batch_size = 1\n",
        "for epoch in range(5):\n",
        "    total_loss = torch.Tensor([0])\n",
        "    np.random.shuffle(randomidx)\n",
        "    classifier.zero_grad()\n",
        "    i = 0\n",
        "    acc = 0\n",
        "    for index in randomidx:\n",
        "        x = txtidx[index].cuda()\n",
        "        probs = classifier(x).cuda()\n",
        "        #loss = loss_function(probs[None,:], labl[index][None,:])\n",
        "        loss = loss_function(probs[0],labl[index].cuda())\n",
        "        loss.backward()\n",
        "        i +=1\n",
        "        if i%batch_size == 0:\n",
        "          optimizer.step()\n",
        "          classifier.zero_grad()\n",
        "        total_loss += loss.data\n",
        "        pred = probs>0.5\n",
        "        if pred.item() == labl[index].item():\n",
        "          acc += 1\n",
        "        if i%2000 == 1999:\n",
        "          print(epoch,i+1,'/',len(randomidx),' : ',total_loss[0].item()/i)\n",
        "    print(epoch, total_loss[0]/len(randomidx),round(acc/i,3))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 2000 / 10000  :  0.7392627588208167\n",
            "0 4000 / 10000  :  0.6801077710833958\n",
            "0 6000 / 10000  :  0.6402043162792758\n",
            "0 8000 / 10000  :  0.5972731454713089\n",
            "0 10000 / 10000  :  0.5643319214733974\n",
            "0 tensor(0.5643) 0.696\n",
            "1 2000 / 10000  :  0.2320008270736931\n",
            "1 4000 / 10000  :  0.2189353338090382\n",
            "1 6000 / 10000  :  0.2168148426756022\n",
            "1 8000 / 10000  :  0.20985980486330322\n",
            "1 10000 / 10000  :  0.20690059728629112\n",
            "1 tensor(0.2069) 0.924\n",
            "2 2000 / 10000  :  0.05923287495188024\n",
            "2 4000 / 10000  :  0.0530112615434132\n",
            "2 6000 / 10000  :  0.049889978000890775\n",
            "2 8000 / 10000  :  0.04976562011657707\n",
            "2 10000 / 10000  :  0.04840059811645227\n",
            "2 tensor(0.0484) 0.99\n",
            "3 2000 / 10000  :  0.012725665009934167\n",
            "3 4000 / 10000  :  0.01350956769191077\n",
            "3 6000 / 10000  :  0.013328554789649186\n",
            "3 8000 / 10000  :  0.012440301490017795\n",
            "3 10000 / 10000  :  0.011854746113039038\n",
            "3 tensor(0.0119) 0.999\n",
            "4 2000 / 10000  :  0.005497547911071014\n",
            "4 4000 / 10000  :  0.005176964864995546\n",
            "4 6000 / 10000  :  0.0052628110976870165\n",
            "4 8000 / 10000  :  0.005180557275775195\n",
            "4 10000 / 10000  :  0.0049657973304654685\n",
            "4 tensor(0.0050) 1.0\n",
            "5 2000 / 10000  :  0.0030735017300367712\n",
            "5 4000 / 10000  :  0.003002779875495607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-49121cfb74df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandomidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxtidx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m#loss = loss_function(probs[None,:], labl[index][None,:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-d9276ab139a4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m#return self.lin(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrxUvOxPyWcG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "4a8b678a-fd60-4d33-be61-a7e607ba7cfe"
      },
      "source": [
        "classifier.eval()\n",
        "\n",
        "M = np.zeros((2,2))\n",
        "for i in range(10000):\n",
        "  probs = classifier(txtidx[i].cuda()).cuda()\n",
        "  if probs > 0.5:\n",
        "    pred = 1\n",
        "  else:\n",
        "    pred = 0\n",
        "  real = int(labl[i])\n",
        "  M[real,pred] += 1\n",
        "print(\"train : \", M)\n",
        "\n",
        "\n",
        "M = np.zeros((2,2))\n",
        "for i in range(10000,20000):\n",
        "  if len(txtidx[i]) > 2:\n",
        "    probs = classifier(txtidx[i].cuda()).cuda()\n",
        "    if probs > 0.5:\n",
        "      pred = 1\n",
        "    else:\n",
        "      pred = 0\n",
        "    real = int(labl[i])\n",
        "    M[real,pred] += 1\n",
        "print(\"val : \", M)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train :  [[5015.    0.]\n",
            " [   0. 4985.]]\n",
            "val :  [[4139.  828.]\n",
            " [ 877. 4111.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14NDrdoEsetK",
        "colab_type": "text"
      },
      "source": [
        "Une question reste : quelle loss utiliser pour le multiLabel ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr0a9SUGsiPc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "2209b6b9-4df5-4d0b-d03b-107111b34ffa"
      },
      "source": [
        "classifier = Conv1D_classifier(vocab_size=vocab_size,embedding_dim=40,out_dim=6,feat_size=20)\n",
        "loss_function = nn.MultiLabelSoftMarginLoss()\n",
        "#loss_function = th.nn.BCELoss()\n",
        "classifier.cuda()\n",
        "optimizer = torch.optim.Adagrad(classifier.parameters(),lr=0.1)\n",
        "total = int(len(txtidx)*1/2)\n",
        "randomidx = list(range(total))\n",
        "preds = torch.zeros((total,6))\n",
        "classifier.train()\n",
        "batch_size = 1\n",
        "for epoch in range(5):\n",
        "    total_loss = torch.Tensor([0])\n",
        "    np.random.shuffle(randomidx)\n",
        "    classifier.zero_grad()\n",
        "    i = 0\n",
        "    \n",
        "    for index in randomidx:\n",
        "        x = txtidx[index].cuda()\n",
        "        probs = classifier(x).cuda()\n",
        "        loss = loss_function(probs[None,:], labl[index][None,:])\n",
        "        #loss = loss_function(probs[0],labl[index].cuda())\n",
        "        loss.backward()\n",
        "        i +=1\n",
        "        if i%batch_size == 0:\n",
        "          optimizer.step()\n",
        "          classifier.zero_grad()\n",
        "        total_loss += loss.data\n",
        "        pred = probs>0.5\n",
        "        \n",
        "        if i%2000 == 1999:\n",
        "          print(epoch,i+1,'/',len(randomidx),' : ',total_loss[0].item()/i)\n",
        "    print(epoch, total_loss[0]/len(randomidx))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 2000 / 10000  :  0.6934789416192472\n",
            "0 4000 / 10000  :  0.6926367211920168\n",
            "0 6000 / 10000  :  0.6919599718442657\n",
            "0 8000 / 10000  :  0.6913569274284286\n",
            "0 10000 / 10000  :  0.6909417504250425\n",
            "0 tensor(0.6909)\n",
            "1 2000 / 10000  :  0.6801283942752626\n",
            "1 4000 / 10000  :  0.6793724798387096\n",
            "1 6000 / 10000  :  0.6798663221213952\n",
            "1 8000 / 10000  :  0.6798414499078009\n",
            "1 10000 / 10000  :  0.6794801550467546\n",
            "1 tensor(0.6795)\n",
            "2 2000 / 10000  :  0.6692844102715421\n",
            "2 4000 / 10000  :  0.6677710687437485\n",
            "2 6000 / 10000  :  0.6684573161282089\n",
            "2 8000 / 10000  :  0.6685946827337792\n",
            "2 10000 / 10000  :  0.6685227604791729\n",
            "2 tensor(0.6685)\n",
            "3 2000 / 10000  :  0.662834652189376\n",
            "3 4000 / 10000  :  0.6631817866576019\n",
            "3 6000 / 10000  :  0.6626381496525463\n",
            "3 8000 / 10000  :  0.6628893186843668\n",
            "3 10000 / 10000  :  0.6627567053580358\n",
            "3 tensor(0.6628)\n",
            "4 2000 / 10000  :  0.6600711244294022\n",
            "4 4000 / 10000  :  0.6600079585326019\n",
            "4 6000 / 10000  :  0.6598289249380105\n",
            "4 8000 / 10000  :  0.6592019681171084\n",
            "4 10000 / 10000  :  0.6590629277771527\n",
            "4 tensor(0.6591)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9PoVZL5vjwd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "3d187aac-11c8-4181-9377-d806c23af839"
      },
      "source": [
        "classifier.eval()\n",
        "\n",
        "j = 2\n",
        "M = np.zeros((2,2))\n",
        "for i in range(10000):\n",
        "  probs = classifier(txtidx[i].cuda()).cuda()\n",
        "  if probs[j] > 0.5:\n",
        "    pred = 1\n",
        "  else:\n",
        "    pred = 0\n",
        "  real = int(labl[i,j])\n",
        "  M[real,pred] += 1\n",
        "print(\"train : \", M)\n",
        "\n",
        "\n",
        "M = np.zeros((2,2))\n",
        "for i in range(10000,20000):\n",
        "  if len(txtidx[i]) > 2:\n",
        "    probs = classifier(txtidx[i].cuda()).cuda()\n",
        "    if probs[j] > 0.5:\n",
        "      pred = 1\n",
        "    else:\n",
        "      pred = 0\n",
        "    real = int(labl[i,j])\n",
        "    M[real,pred] += 1\n",
        "print(\"val : \", M)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train :  [[7293.   61.]\n",
            " [1409. 1237.]]\n",
            "val :  [[7147.  252.]\n",
            " [1823.  733.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FjoPBtB1rhn",
        "colab_type": "text"
      },
      "source": [
        "## Amelioration (paper 2014)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYA70Gva1MdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv1D_classifier_2(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim,out_dim, feat_size=5):\n",
        "        super(Conv1D_classifier_2, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embeddings = nn.Embedding(\n",
        "                num_embeddings=vocab_size,\n",
        "                embedding_dim=embedding_dim)\n",
        "        \n",
        "        \n",
        "        self.conv1 = nn.Conv1d(embedding_dim,feat_size,3,padding=1)\n",
        "        self.conv2 = nn.Conv1d(embedding_dim,feat_size,5,padding=2)\n",
        "        self.conv3 = nn.Conv1d(embedding_dim,feat_size,7,padding=3)\n",
        "        \n",
        "        self.lin = nn.Linear(feat_size*3,out_dim)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embs = self.embeddings(inputs)\n",
        "        tmp=embs.view(1,self.embedding_dim,-1)\n",
        "        outconv = []\n",
        "        outconv.append(self.conv1(tmp))\n",
        "        outconv.append(self.conv2(tmp))\n",
        "        outconv.append(self.conv3(tmp))\n",
        "        tmp = torch.cat(outconv, 1)\n",
        "        out = nn.MaxPool1d(tmp.shape[-1])(tmp)\n",
        "        out = out.view(out.shape[1])\n",
        "        out = self.dropout(out)\n",
        "        return self.activation(self.lin(out))\n",
        "        #return self.lin(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17A66F4P2xdg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a6eb46b-2bf3-43fd-e9a6-e20f8d3f90ae"
      },
      "source": [
        "classifier = Conv1D_classifier_2(vocab_size=vocab_size,embedding_dim=35,out_dim=1).cuda()\n",
        "\n",
        "#loss_function = nn.MultiLabelSoftMarginLoss()\n",
        "loss_function = th.nn.BCELoss()\n",
        "classifier.cuda()\n",
        "optimizer = torch.optim.Adagrad(classifier.parameters(),lr=0.08)\n",
        "total = int(len(txtidx)*1/2)\n",
        "randomidx = list(range(total))\n",
        "preds = torch.zeros((total,6))\n",
        "classifier.train()\n",
        "batch_size = 1\n",
        "for epoch in range(10):\n",
        "    total_loss = torch.Tensor([0])\n",
        "    np.random.shuffle(randomidx)\n",
        "    classifier.zero_grad()\n",
        "    i = 0\n",
        "    acc = 0\n",
        "    for index in randomidx:\n",
        "        try:\n",
        "          x = txtidx[index].cuda()\n",
        "          probs = classifier(x).cuda()\n",
        "          #loss = loss_function(probs[None,:], labl[index][None,:])\n",
        "          loss = loss_function(probs[0],labl[index].cuda())\n",
        "          loss.backward()\n",
        "          i +=1\n",
        "          if i%batch_size == 0:\n",
        "            optimizer.step()\n",
        "            classifier.zero_grad()\n",
        "          total_loss += loss.data\n",
        "          pred = probs>0.5\n",
        "          if pred.item() == labl[index].item():\n",
        "            acc += 1\n",
        "          if i%2000 == 1999:\n",
        "            print(epoch,i+1,'/',len(randomidx),' : ',total_loss[0].item()/i)\n",
        "        except RuntimeError:\n",
        "          ()\n",
        "    print(epoch, total_loss[0]/len(randomidx),round(acc/i,3))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 2000 / 10000  :  0.7386058752032266\n",
            "0 4000 / 10000  :  0.7170285613395536\n",
            "0 6000 / 10000  :  0.7034098782088681\n",
            "0 8000 / 10000  :  0.691831168837511\n",
            "0 10000 / 10000  :  0.6764208647427242\n",
            "0 tensor(0.6764) 0.58\n",
            "1 2000 / 10000  :  0.523586072821567\n",
            "1 4000 / 10000  :  0.4967209514781039\n",
            "1 6000 / 10000  :  0.49069205219099016\n",
            "1 8000 / 10000  :  0.4763310562746125\n",
            "1 10000 / 10000  :  0.4686456926942694\n",
            "1 tensor(0.4686) 0.774\n",
            "2 2000 / 10000  :  0.3219040550548712\n",
            "2 4000 / 10000  :  0.3220206907195549\n",
            "2 6000 / 10000  :  0.32115954465718244\n",
            "2 8000 / 10000  :  0.31621796352473747\n",
            "2 10000 / 10000  :  0.3110673127859661\n",
            "2 tensor(0.3110) 0.866\n",
            "3 2000 / 10000  :  0.2463763925419741\n",
            "3 4000 / 10000  :  0.23683076836103556\n",
            "3 6000 / 10000  :  0.23198619447642316\n",
            "3 8000 / 10000  :  0.22488655503324634\n",
            "3 10000 / 10000  :  0.2207744700251275\n",
            "3 tensor(0.2208) 0.912\n",
            "4 2000 / 10000  :  0.14807403701850924\n",
            "4 4000 / 10000  :  0.15262464297715053\n",
            "4 6000 / 10000  :  0.1494755249735633\n",
            "4 8000 / 10000  :  0.1511073130967543\n",
            "4 10000 / 10000  :  0.15034160886791803\n",
            "4 tensor(0.1503) 0.942\n",
            "5 2000 / 10000  :  0.10828253482209856\n",
            "5 4000 / 10000  :  0.11222905366234137\n",
            "5 6000 / 10000  :  0.10786538967432072\n",
            "5 8000 / 10000  :  0.10521629229532597\n",
            "5 10000 / 10000  :  0.10496457360579808\n",
            "5 tensor(0.1050) 0.962\n",
            "6 2000 / 10000  :  0.07792680367283251\n",
            "6 4000 / 10000  :  0.08312373198280039\n",
            "6 6000 / 10000  :  0.08195922159715421\n",
            "6 8000 / 10000  :  0.08056285813802898\n",
            "6 10000 / 10000  :  0.07780737790575933\n",
            "6 tensor(0.0778) 0.973\n",
            "7 2000 / 10000  :  0.04958788903729208\n",
            "7 4000 / 10000  :  0.05371864129972923\n",
            "7 6000 / 10000  :  0.0534035488255204\n",
            "7 8000 / 10000  :  0.05338063498171646\n",
            "7 10000 / 10000  :  0.05381316329875175\n",
            "7 tensor(0.0538) 0.983\n",
            "8 2000 / 10000  :  0.04007803004285346\n",
            "8 4000 / 10000  :  0.03828157738287111\n",
            "8 6000 / 10000  :  0.04279453680105538\n",
            "8 8000 / 10000  :  0.04356320754693946\n",
            "8 10000 / 10000  :  0.04373247078125781\n",
            "8 tensor(0.0437) 0.987\n",
            "9 2000 / 10000  :  0.03612511822317409\n",
            "9 4000 / 10000  :  0.03494492779078559\n",
            "9 6000 / 10000  :  0.03419056628660115\n",
            "9 8000 / 10000  :  0.03406900929754891\n",
            "9 10000 / 10000  :  0.03260691974959214\n",
            "9 tensor(0.0326) 0.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sWrX_083Fyd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "939f7562-0359-43a7-ada8-e7d5964fd34f"
      },
      "source": [
        "classifier.eval()\n",
        "\n",
        "M = np.zeros((2,2))\n",
        "for i in range(10000):\n",
        "  try:\n",
        "    probs = classifier(txtidx[i].cuda()).cuda()\n",
        "    if probs > 0.5:\n",
        "      pred = 1\n",
        "    else:\n",
        "      pred = 0\n",
        "    real = int(labl[i])\n",
        "    M[real,pred] += 1\n",
        "  except RuntimeError:\n",
        "    ()\n",
        "print(\"train : \", M)\n",
        "\n",
        "\n",
        "M = np.zeros((2,2))\n",
        "for i in range(10000,20000):\n",
        "  try:\n",
        "    probs = classifier(txtidx[i].cuda()).cuda()\n",
        "    if probs > 0.5:\n",
        "      pred = 1\n",
        "    else:\n",
        "      pred = 0\n",
        "    real = int(labl[i])\n",
        "    M[real,pred] += 1\n",
        "  except RuntimeError:\n",
        "    ()\n",
        "print(\"val : \", M)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train :  [[5.018e+03 5.000e+00]\n",
            " [1.000e+00 4.975e+03]]\n",
            "val :  [[4170.  806.]\n",
            " [ 818. 4205.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl3v8FgF4oeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}